{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQwVlwzkPF/9pGEVJzbzhN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "Z5sflcEYSgxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZEFVyFhR9J3",
        "outputId": "1bad6307-b5d1-42ee-fdf6-7cff9bba751c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentence = \"Programmers, love programming using programming language\"\n",
        "print(\"Everyone: \", lemmatizer.lemmatize(\"rocks\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Wi3TOBSts8",
        "outputId": "9e168efb-adf5-48d9-f996-340ac70c325d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everyone:  rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Stemming"
      ],
      "metadata": {
        "id": "9CnIhduQTNEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "hTTCQ2ruS5Ob"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
        "for w in words:\n",
        "  print(w, \" : \", ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmVZgkA5TYQl",
        "outputId": "627e8c3f-c66b-40a0-de9b-b2f9ec792281"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programmer  :  programm\n",
            "programming  :  program\n",
            "programmers  :  programm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Programmers program with programming languages\"\n",
        "words = word_tokenize(sentence)\n",
        "for w in words:\n",
        "  print(w, \" : \", ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjd0ebtOTops",
        "outputId": "6cf5a6d2-e6bf-4d4e-b22b-f60ef8d8c444"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Programmers  :  programm\n",
            "program  :  program\n",
            "with  :  with\n",
            "programming  :  program\n",
            "languages  :  languag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Stop word removal"
      ],
      "metadata": {
        "id": "F1Lx8_4gUc-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "file_name = '/content/file.txt'\n",
        "with open(file_name, 'r') as file:\n",
        "  text = file.read()\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "filtered_sentence = [w for w in tokens if w.lower() not in stop_words]\n",
        "filtered_text = \" \".join(filtered_sentence)"
      ],
      "metadata": {
        "id": "sEUQz_zUVuaC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkgib0YtDHUG",
        "outputId": "2ad322cd-d0a9-4861-cc2c-da53ea65efdc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hii , hello student college , let know need anything .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# TFIDF"
      ],
      "metadata": {
        "id": "b4MgVQABXW-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "YC5hCopfYTiM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = \"Everyone welcome to New York\"\n",
        "d2 = \"New York is an amazing city\"\n",
        "d3 = \"Instead of that city go to Delhi\"\n",
        "series = [d1, d2, d3]"
      ],
      "metadata": {
        "id": "yd7p2xHpDylw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf = TfidfVectorizer()\n",
        "result = tf_idf.fit_transform(series)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBVsf0vDEDZ1",
        "outputId": "f3f48017-2e2c-4ad4-c099-c98d0e77d6f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 13)\t0.39351120409397233\n",
            "  (0, 8)\t0.39351120409397233\n",
            "  (0, 11)\t0.39351120409397233\n",
            "  (0, 12)\t0.5174199439321682\n",
            "  (0, 4)\t0.5174199439321682\n",
            "  (1, 2)\t0.3494981241087058\n",
            "  (1, 0)\t0.45954803293870056\n",
            "  (1, 1)\t0.45954803293870056\n",
            "  (1, 7)\t0.45954803293870056\n",
            "  (1, 13)\t0.3494981241087058\n",
            "  (1, 8)\t0.3494981241087058\n",
            "  (2, 3)\t0.40301621080355077\n",
            "  (2, 5)\t0.40301621080355077\n",
            "  (2, 10)\t0.40301621080355077\n",
            "  (2, 9)\t0.40301621080355077\n",
            "  (2, 6)\t0.40301621080355077\n",
            "  (2, 2)\t0.3065042162415877\n",
            "  (2, 11)\t0.3065042162415877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_idf.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9x8SBv_EO6b",
        "outputId": "2cfbf66c-545f-4534-a0c8-5990e439f76b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'everyone': 4, 'welcome': 12, 'to': 11, 'new': 8, 'york': 13, 'is': 7, 'an': 1, 'amazing': 0, 'city': 2, 'instead': 6, 'of': 9, 'that': 10, 'go': 5, 'delhi': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# POS Tagging"
      ],
      "metadata": {
        "id": "f9sJVKiNEwIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5lwz0H6Eaxg",
        "outputId": "50d0b3de-481a-4647-ebc5-0e19b6f17049"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_text = ['Leaves', 'Leaf', 'Play']\n",
        "ps = pos_tag(p_text)\n",
        "for p in ps:\n",
        "  print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiDKU-cvFLxx",
        "outputId": "8e84bf29-6e2a-4838-cab2-ca8d9e3bf5bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Leaves', 'NNS')\n",
            "('Leaf', 'NNP')\n",
            "('Play', 'NNP')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_pos = \"I love playing with my sister\"\n",
        "wording = word_tokenize(sentence_pos)\n",
        "pos_tagiing = pos_tag(wording)\n",
        "for word in pos_tagiing:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEMnur4FUFs",
        "outputId": "192b32b9-8d7c-4153-e6e8-b0383224281a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I', 'PRP')\n",
            "('love', 'VBP')\n",
            "('playing', 'VBG')\n",
            "('with', 'IN')\n",
            "('my', 'PRP$')\n",
            "('sister', 'NN')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_REIy1cxGN8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}